Breast Cancer detection Using Convolutional Neural Networks for Mammogram Imaging System 
Y. J. Tan, K. S. Sim, and F. F. Ting 
Faculty of Engineering & Technology, 
Multimedia University, Jalan Ayer Keroh Lama, 
75450 Melaka, Malaysia. 
tanyjun@gmail.com; sksbg2015@gmail.com; sicily.ting@gmail.com 
 AbstractŠ
 In this paper, breast cancer detection using 
convolutional neural network for mammogram imaging system is 
proposed to classify mammogram image into normal, benign(non-

cancerous abnormality) and malignant (cancerous abnormality). 
Breast Cancer detection Using Convolutional Neural Networks 
(BCDCNN) is aimed to speed up the diagnosis process by assisting 
specialist to diagnosis and classification the breast cancer. A series 

of mammogram images are used to carry out  preprocessing to 
convert a human visual image into a computer visual image and 
adjust suitable parameter for the CNN classifier. After that, all 
changed images are assigned into CNN classifier as training source. 

The CNN classifier will then produce a model to recognize the 
mammogram image. By comparing BCDCNN method with 
Mammogram Classification Using Convolutional Neural 
Networks (MCCNN), BCDCNN has improved the accuracy 

toward classification on the mammogram images.Thus, the results 

show that the proposed method has higher accuracy than other 
existing methods,
 mass only and all argument have been increased 
from 0.75 to 0.8585 and 0.608974 to 0.8271 accuracy. 
I.  INTRODUCTION
 Breast cancer is an important risk that must be concerned by 
everyone around the world. With almost 1.7 million new cases 
diagnosed in 2012, breast cancer is the most common form of 
cancer around the world [1]. In 2017, estimated 252,710 new 
invasive breast cancer cases will be developed in women, along 
with 63,410 of non-invasive breast cancer case, and 40,610 case 

breast cancer deaths [2]. There are many breast cancer risk 

factors, such as family history, medical history, and age.  
 According to a study for Breast Cancer Care, we have 
discovered that 42% of National Health Service (NHS) trusts 
say that they do not have the staff to assign individuals with 

limited breast cancer specialist nurse [3]. It is the most 

important reason that can cause low survival rate of breast 
cancer all around the world. Due to lack of breast cancer 
specialist nurse or doctor, it will cause late diagnosis of breast 

cancer, lack of compliance to optimal detection or treatment, 

and inequity of access to optimal treatment. Therefore breast 

cancer detection is developed to perform effectiveness in both 

abnormalities and classification breast detection. This is to 
assist and diagnose the breast cancer. 
 
Diagnostic medical imaging is the most fundamental 
approach in the act of current solution. There are a lot of 

methods to obtain medical image, such as Magnetic Resonance 
Imaging (MRI), mammography, X-ray, and Ultrasound. 
Normally, mammography and MRI are used for breast cancer 
diagnosis. Besides, mammogram is a fast procedure which 

takes only about 20 minutes. The whole process is just an 

extremely small measure of radiation exposure from a 
mammogram which is safe than other treatment [4]. Moreover, 
late treatment will leave irreversible effects on the patient™s 
health. Mammogram is chosen to solve the problem to increase 

the percent of women being treatment. 
 A new approach of image recognition system with breast 
cancer detection is proposed. This image recognition system is 
using convolutional neural network, which is a type of artificial 

neural network designed and successfully used to recognize 

visual imagery. This system is able to classify and detect 
abnormalities in mammograms image. In general, a 
mammogram image can be classified into malignant (cancerous 
abnormality), benign (non-cancerous abnormality), or normal.  
 Googles open source Machine Learning library, 
TensorFlow is  used for this model [5]. This classifier tested 
data is obtained from mini-Mammographic Image Analysis 
Society (mini-MIAS) database. This classifier has been 
modified, through some methods, such as pixel size of input 
image, kernel size, learning rate, step number, number of hidden 

layers, and other. 
II. PROBLEM 
STATEMENT
  Some previously completed research was used to 
understand the types of breast cancer, types of medical image 
used for classification, types of neural network for image 
classification. Tensorflow tutorial on Convolutional Neural 

Network is official method that uses CNN. There is an example 

on CIFAR-10 classification with various overfitting, good 

training, and performance boosting techniques [5]. ImageNet 
Classification with Deep Convolutional Networks is designed 
to category machine learning and image classification [6]. 
Many of techniques that use on model have references from [6]. 

They are the preprocessing techniques idea. 

   Consequently, some works focus on Classification of breast 
cancer histology. The latest version of histology image 
classification by using CNN, but histology image has its 

limitation which it is takes long time for the lab usage [7]. 
Reference [8] is the most cited paper that use MRI image for 
classification by using ANN, but MRI has a lot of radiation 
exposures that may harm to human health. However, 
mammogram image is the most suitable target for this work, 
since it is cheap than other treatment, and has very tiny 
radiation 
exposure from mammogram [8]. Therefore, many patients can 
have early checking if a faster mammograms image has been 

diagnosed. But mammogram also has its limitations for 

example some not clearly cancer cannot be scanned. 

  Some previously completed paper had used different types 
of neural network for classification mammogram image in 
breast cancer. Reference [9] is for the prediction of breast 
cancer by using artificial neural networks for classification and 
prediction [9]. The wavelet neural network is employed for 
breast cancer diagnosis [10]. Both neural networks are designed 
for general decision making purpose, so both of them need to 
setup many parameters than CNN which is designed for purpose 
recognize visual imagery. Same number of hidden layer, 
standard neural networks working on processing visual imagery 

need have 3x10
6 parameters. But for CNN, it only needs around 
600 parameters for processing visual imagery. 
 Reference [11] suggested a mammogram image detection 
using CNN. But the accuracy percentage is too low for a 

medical side solution which is around 60% for all classes 

detection, 75% for only masses class, and 100% for only 

calcification. Except only calcification argument, all argument 
and mass only argument can further be improved the accuracy 
to get a better performance [11]. 
III. METHODOLOGY
 A. Dataset 
In this experiment, mini-Mammographic Image Analysis 
Society (mini-MIAS) database of mammograms image has 
been used as experiments target [12], mini-MIAS is a database 
that reduces the size of the image by changing original image 

from 50 micron pixel edge to 200 micron pixel edge. There are 
322 grayscale mammograms (161 pair of patient) with 
dimension of 1024 x1024 pixels. 
 Fig. 1.   Mammogram image with labelled data 
 Some important information has come with mini-MIAS 
dataset. Every data has labelled with character of background 

tissue and class of abnormality. Another information that given 
for abnormalities data is the severity of abnormality that present 
such as benign or malignant, x and y coordinates for centre of 

abnormality, and the abnormality radius measurement of pixels 
form. Fig. 1 is a mammogram image with labeled data 
explanation.
  B. Image Preprocessing
 The raw data pixel size is too large. Huge segment of time 
is spent to adjust the input data for the classifier. Accordingly, 
most breast cancer tissue size is less than 20% percent from a 
1024 x1024 pixel raw data, so it will affect the accuracy of the 
classifier performance and computation time. For a large pixels 

data as input of CNN classifier, it will spend a lot of 
computation time for every not necessary information or not 

important noise. At the same time, it also will affect the last 
result for the classifier. 
 In order to get only the important data, abnormality tissue is 
cropped and used in the CNN classifier. Fig. 2 shows examples 

of benign tissue. Fig. 3 shows example of malignant tissue. 

These images are cropped out by using mini-MIAS with the 
given X, Y coordinate and radius from the center point, after 
cropped resize it to 48 x 48 for uniform dimension as input of 

CNN classifier. 
 Fig. 2.  Benign images before training 
Fig. 3.  Malignant tissues before training 
  Fig. 4.  Normal tissues before training 
 Fig. 4 shows the example of cropped normal tissue which is 
randomly cropped in order to make the CNN to classify smart 

which can identity normal patient also. Every image has been 
cropped at random spot at uniform dimension 48 pixel x 48 
pixel.  

  To increase the accuracy of the model, we has subsampled 
the dataset by using image transformations. Rotation 90, 180, 
270 degrees have been added into dataset. Horizontally 
reflected version for every rotation has also added to the dataset 

for train the system not only recognizes the fix position; but also 
can detect the abnormality smartly. 
 There are some abnormality tissues which are too close to 
limitation of mammograms such as examples shown in Fig. 5. 

When cropped out the image by giving labelled position and 
radius, it will has an blank area which is limitation area for 
mammogram, but the back blank may effect to the result of 

classifier. These types of data have been removed from the 

dataset for better accuracy. 
    
Fig. 5.  Examples of bad train dataset 
 C. 
TensorFlow
  TensorFlow library has been selected as model for the 
Machine Learning framework. It is a Google open source 
software library for Machine Intelligence [5]. It was made open 

source since November of 2015, before that it was only used by 

Google Brain team for machine intelligence or artificial 

intelligence research. Compare to other Machine Learning 

framework, TensorFlow is support Window system without 
install any other dependent. Most popular frames like caffe still 
not supporting Window system. These frameworks all designed 

for Linux system. However it still can be used on window. It 

also faces many warning and trouble when using it. TensorFlow 

API r1.3 has been used on BCDCNN. It has a new estimator 
which updated on March 2017, estimated the CNN by training 
data, evaluated data and predict the data without using 

dependent resource. 

 
D. Convolutional Neural Network 
 Convolutional neural Network is made up of neurons that 
have learnable weights and biases. Each neuron receives some 
inputs. Then performs new a dot product and optionally follows 

it with a non-linearity. The whole network still expresses a 
single differentiable score function: from the raw image pixels 
on one end to class scores at the other.  

  Convolutional Neural Networks take advantage of the fact 
that the input consists of images and they constrain the 

architecture in a more sensible way. In particular, unlike a 
regular Neural Network, the layers of a CNN have neurons 
arranged in 3 dimensions: width, height, depth as shown in Fig. 

6.  Fig. 6.  A Convolutional Neural Network neuron arrangement [14] 
 A convolutional Neural Networks is a combination of many 
types of layers. As BCDCNN, method there are included input 
layer, 2 hidden layer, and output layer. Input layer is the image 

data that we input by pixel. In this model, grayscale 
mammograms as the input so it will have 48 x48 x1 input data 
for the CNN. 

  In hidden layer, there are many layers included such as 
convolutional layer, rectified linear unit (ReLU) layer, Pooling 

layer, Fully-connected (Dense) layer. Simple explanation for 

hidden layer is shown in Fig. 7. 
 Fig. 7.  Convolutional Neural Network process 
  Convolutional layers applied specified number of 
convolution filters to the image. For each subregion, the layer 

performs a set of mathematical operations to produce a single 
value in the output feature map as shown in Fig.7. 
Convolutional layers then typically apply a ReLU activation 
function to the output to introduce nonlinearities into the model. 
BCDCNN model has an input of 48 x 48 matrix and filter it into 

32 features image by using kernel size of 5x5 filter with ReLU 

activation as Fig. 8. 
 Fig. 8.  Convolution matrix with a 3x3 kernel [13] 
  Fig. 9.  ReLU activation function 
 Pooling layers downsamples the image spatially. A 2x2 
filter max pooling example is shown in Fig. 10. A 2 x 2 filter is 

then applied on a matrix. The biggest number will be stored and 
the rest will be removed. It will then move 2 pixels to do another 

filter when we are given a stride value of 2. Purpose of this layer 
is to decrease the processing time. 
  Fig. 10.  Pooling layer in Convolutional neural network [14] 
  Same with other CNN model, BCDCNN uses back 
propagation for update weight for latest their closer value. 
When training the data, every time new image passes through 
the layer and a loss data will produce when comparing it out 

with expected output. By using this error, the model can update 
the network to improve it accuracy.  

  Last is Fully Connected Layers, This layer is a decision 
making layer. In this classifier, dense layer connected last 

hidden layer (7 * 7 * 64) into a 1024 node. Every node in layer 

will connect every node in the logits layer. In our model, the 

logits layer will have 3 types of possible output which is 0 for 

normal, 1 for benign, and 2 for malignant.  
  There are many parameters and methods to improve a CNN 

model, such as increase the data size, change on the training step, 

change on the learning rate, increase the pixel of the data for 

input layer, increase the hidden layer, and feature number. But 

model will be overfitting if getting too high learning rate and 
training step. There will make the model not flexible to be tested 
as a new input data.  
IV. RESULT
 AND
 DISCUSSION 
 As comparison a regular Neural Network that uses to 
process our model data has 48*48*1= 2304 weight parameters. 
For CNN model with a 32 feature map, it will only has 32 
unique set weight parameters [14]. 

  
 three types of version have been created. Version 1 is a Full 

Classification Example with ConvNet on Kaggle which 

classifies a batch of image into cat and dog [15]. It uses whole 
image as input. But the predicted outputs are wrong, when 
comparing without labeled data set for a medical side research. 

A true result is important than other component. 

   Version 2 is to follow the TensorFlow official guideline to 

develop a CNN model and scale down the whole image as the 
input data. However the true positive and true negative have 
been confirmed by given label to all input data when training 

and evaluation are conducted. The model will follow the label 

to train the classes. When evaluation is conducted, it will make 

a prediction on an image and compare it to given label. But once 
we use whole mammogram images as input, the size of breast 
cancer tissue is small than 20% from whole image so it will 

make the model more confusing the target to be classification. 

In this version we only get a very low accuracy. 
  Version 3 which is the current version. The model uses 
TensorFlow official guideline but the input data is the 

preprocessing data. The true positive and true negative have 
remained high due to given label to be tested and accuracy was 
increase to 0.827 which mean 82.7%. This model uses 48x48 as 

input, convolution layer with kernel size 5x5 filter, pooling 

layer with pool size 2x2 filter and strides of 2, learning rate with 

0.003, training step with 20,000. 
 TABLE I. COMPARISON BETWEEN THREE VERSION 
 Version Version 1 Version 2 Version 3 
True Positive 297 458 697 
True Negative 597 916 1394 
False Positive 1088 769 291 
False Negative 544 385 146 
Calculations 
False Positive Rate 64.57% 45.64% 17.27% 
False Negative Rate 64.68% 45.68% 17.32% 
Sensitivity 35.32% 54.32% 82.68% 
Specificity 35.43% 54.36% 82.73% 
Accuracy 38.45% 54.35% 82.71% 
  Fig. 11.  Compare to existing CNN method on mammogram 
  Compared BCDCNN model with existing CNN Zhou et al 
paper, a comparison figure has shown in Fig. 11 [11]. The 
comparison is formed in all argument, mass argument and 
calcification argument.  It is our target to improve the accuracy 
in all categories. Except calcifi
cation argument was 100% in 
both paper, mass and all argument have been increased from 

0.75 to 0.8585 and 0.608974 to 0.8271 accuracy.
  As the given dataset, over 60% is normal case. It may affect 
the balancing of the classifier to class the input in to 3 categories 
equally. To solve this problem. Both paper have classified for 

only calcification (0 normal, 80 Benign, 104 Malignant) and 

only mass (0 normal, 280 Benign, 144 Malignant). It is found 
that a mass only has around double of the data compare between 
benign and malignant, This may be the reason to cause the 
classifier confusing for BCDCNN model. Calcification only 

model has balance data between benign and malignant. This 

may be the reason to make classifier easier to form good model 
to classifier the input data.
   Lastly in this experiment, we have limitation to get more 
data. More mammograms need to train a better model, but it is 
00.20.40.60.811.2
All argument
Mass argument
Calcification argument
Compare to existing CNN method 
on mammogram
BCDCNN
MCCNN
less open source research data. Besides that, my knowledge on 
breast cancer may cause limitation of BCDCNN model. All of 

the breast cancer location or accuracy follow the given labelled 
data, we are difficult to identity every tissue and cell from 
mammogram ourself. There are difficult to set a perfect setting 

of parameters. It will cause around a day for 1 run, but need to 

restart the training once changing the parameter. It is consumed 

much of time for the project. If we want to train faster, more 

hidden layer or more input pixel higher performance processer 
are required.
  V. CONCLUSION 
 The new version of breast cancer detection by using 
Convolutional Neural Network has been proposed and 

developed. This system classifies mammogram images into 3 

categories: normal, benign and malignant with high rate than 

80%. The system which can assist and help the doctor or 

specialist nurse to speed diagnosed the mammograms, to cover 
shortage of specialist or time handling diagnosed, every person 
can do a simple diagnosed though the system. 
    The method starts with preprocessing the mammograms to 
an image that can be easily recognize by a computer. The CNN 

model will find out different between every labelled data by 
using many types of feature getting from the image. After 
20,000 times of comparison, it will come out a model that able 

to classification input image into closer possible output. The 

model only needs to train once. For the evaluation on predict 

images, it only takes few minutes to complete without times 

limit except any parameter that needs to change. Then, the 
model need to retrain for few day.  
  In conclusion, the 
breast cancer detection by using 
Convolutional Neural Network
 had been successfully 
developed and tested with 322 of mammogram images. This 
method provides a fast diagnosis time and high accuracy system. 
 REFERENCES
  [1]
 J. Ferlay, I. Soerjomataram I, M. Ervik, R. Dikshit, A. Eser, C. Mathers, 
M. Rebelo, D.M. Parkin, D. Forman and F. Bray. GLOBOCAN 2012 v1.1, 
Cancer Incidence and Mortality Worldwide: IARC CancerBase No. 11 . 
[2]
 ﬁU.S. Breast Cancer Statisticsﬂ Breastcancer.org 120 East Lancaster 
Avenue, Suite 201 Ardmore, PA 19003 web. Available: 
http://www.breastcancer.org/
. Last accessed : 29 Sept 2017. 
[3]
 Breast Cancer Care.ﬁThree quarters of NHS Trusts and Health Boards say 
"not enough" care for incurable breast cancer patientsﬂ breast cancer care 

pink ribbon 25. Sophie Softley Pierce, PR Manager, Breast Cancer Care. 

Available: 
https://www.breastcancercare.org.uk/about-us/media/press-
releases/three-quarters-nhs-trusts-health-boards-say-not-enough-care-
incurable
 Last Accessed: 02 October 2017. 
[4]
 Breast Cancer. ﬁMammography: Benefits, Risks, What You Need to 
Knowﬂ Breastcancer.org Susan Greenstein Orel, M.D . Available: 

http://www.breastcancer.org/symptoms/testing/types/mammograms/bene
fits_risks
 Last Accessed: 02 Octorber 2017. 
[5]
 TensorFlow . Available: 
https://www.tensorflow.org/
 Last Accessed: 2 
Octorber 2017. 
[6]
 A. Krizhevsky, L. Sutskever,& G. E. Hinton, ﬁImagenet classification 
with deep convolutional neural networks.ﬂ In Advances in neural 
information processing systems , pp.1097-1105, 2012. 
[7]
 T. Araújo, G. Aresta, E. Castro, J. Rouco, P. Aguiar, C. Eloy,  & A. 
Campilho. ﬁClassification of breast cancer histology images using 
Convolutional Neural Networks,ﬂ PloS one, vol.12(6), e0177544, 2017. 
[8]
 J. Khan, J. S. Wei, M. Ringner, L. H. Saal, M. Ladanyi, F. Westermann, 
and P.S. Meltzer, ﬁ Classification and diagnostic prediction of cancers 
using gene expression profiling and artificial neural networks,ﬂ Nature 
medicine,vol. 7(6), pp. 673, 2001. 
[9]
 I. Saratas, "Prediction of breast cancer using artificial neural networks," 
Journal of Medical Systems, vol. 36(5 ),pp. 2901-2907, 2012. 
[10]
 V. Dheeba,  N.A. Singh, and J. A. P.  Singh, "Breast Cancer Diagnosis: 
An Intelligent Detection System Using Wavelet Neural Network," 

Proceedings of the International Conference on Frontiers of Intelligent 

Computing: Theory and Applications (FICTA) 2013. Springer, Cham, 
2014. 
[11]
 H. Zhou, Y. Zaninovich,and C.  Gregory,  ﬁMammogram Classification 
Using Convolutional Neural Networksﬂ, Vaialable: 

http://ehnree.github.io/documents/papers/mammogram_conv_net.pdf
 Last Accessed: 02 October 2017. 
[12]
 J. Suckling, J. Parker, D. Dance, S. Astley, I. Hutt, C. Boggis, and P. 
Taylor, ﬁ The mammographic image analysis society digital mammogram 

database,ﬂ In Exerpta Medica. International Congress Series , vol. 1069, 
pp. 375-378, July 1994. 
[13]
 H. H. Wang, and  B. Raj, ﬁA Survey: Time Travel in Deep Learning Space: 
An Introduction to Deep Learning Models and How Deep Learning 

Models Evolved from the Initial Ideas,ﬂ CoRR,  arXiv:1510.04781, 
2015. 
[14]
 A. Karpathy. CS231n: Convolutional Neural Networks for Visual 
Recognition. Stanford University. Avaialable: 
http://cs231n.stanford.edu/
 Last Accessed: 2 October 2017. 
[15]
 Sentdex(2016) Full Classification Example with ConvNet  
Retrieved from: 
https://www.kaggle.com/sentdex/full-classification-
example-with-convnet
. Last Accessed: 2 October 2017.
 